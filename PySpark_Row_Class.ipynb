{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark Row Class.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt4ADF0PjfZO",
        "outputId": "5f8bf627-4b07-424d-c615-5d2a5c876081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 64.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=3abf9586ddd7d330a4dc57d7f964cd8b6d23ad6043bf1de0133464c7e650b070\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "XGjM1AcbkD-B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName('Pyspark Row Class').getOrCreate()"
      ],
      "metadata": {
        "id": "RbSFypOYkL8T"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating row object\n",
        "from pyspark.sql import Row\n",
        "row = Row('java',100)\n",
        "print(row[0],row[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHPTViYmkeps",
        "outputId": "7fe29f5f-a77f-4721-fd3d-5f80f40bcd3a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "java 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or \n",
        "row = Row(lang=\"java\",count=100)\n",
        "print(row.lang)\n",
        "print(row.count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR6s14PjlEMR",
        "outputId": "a0c22e5e-c697-48ed-dfb8-6234dc9d5827"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "java\n",
            "<built-in method count of Row object at 0x7f0a5730bb30>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creaating a custom class from row\n",
        "Data = Row(\"lang\",\"count\")\n",
        "d1= Data(\"Java\",100)\n",
        "d2= Data(\"C\",89)\n",
        "print(d1[\"lang\"],d2.lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A9kePfjlsPH",
        "outputId": "3df1b328-1576-4888-b170-e284f27d6618"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Java C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using row class on rdd\n",
        "data = [Row(name=\"Jack,,Sparrow\",lang=[\"Java\",\"C++\"]), \n",
        "    Row(name=\"Ema,Rose,\",lang=[\"Spark\",\"Java\",\"C\"]),\n",
        "    Row(name=\"Bootstrap,,Turner\",lang=[\"C\",\"Python\"])]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "res= rdd.collect()\n",
        "for i in res:\n",
        "  print(i.name,i.lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akeXD9gSmqGN",
        "outputId": "726d6f14-387e-4a3b-ddc0-8154bbd40d4d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jack,,Sparrow ['Java', 'C++']\n",
            "Ema,Rose, ['Spark', 'Java', 'C']\n",
            "Bootstrap,,Turner ['C', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# or\n",
        "Data= Row(\"name\",\"lang\")\n",
        "data = [Data(\"Jack,,Sparrow\",[\"Java\",\"C++\"]), \n",
        "    Data(\"Ema,Rose,\",[\"Spark\",\"Java\",\"C\"]),\n",
        "    Data(\"Bootstrap,,Turner\",[\"C\",\"Python\"])]\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "res= rdd.collect()\n",
        "for i in res:\n",
        "  print(i.name,i.lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlwQxOxcnhWn",
        "outputId": "c43029ca-c5bc-48aa-89ad-57a1cd76d508"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jack,,Sparrow ['Java', 'C++']\n",
            "Ema,Rose, ['Spark', 'Java', 'C']\n",
            "Bootstrap,,Turner ['C', 'Python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Row class on PySpark DataFrame\n",
        "df= spark.createDataFrame(data)\n",
        "df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nxxwSSfn_Gh",
        "outputId": "1c5559a9-5f3c-4570-def4-a0c9733c4411"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------------+\n",
            "|         name|            lang|\n",
            "+-------------+----------------+\n",
            "|Jack,,Sparrow|     [Java, C++]|\n",
            "|    Ema,Rose,|[Spark, Java, C]|\n",
            "+-------------+----------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col = [\"Name\",\"languages\"]\n",
        "df=spark.createDataFrame(data).toDF(*col)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZMkspinoaWt",
        "outputId": "b4e75d6c-c9b8-4548-b87d-19442155e41f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----------------+\n",
            "|             Name|       languages|\n",
            "+-----------------+----------------+\n",
            "|    Jack,,Sparrow|     [Java, C++]|\n",
            "|        Ema,Rose,|[Spark, Java, C]|\n",
            "|Bootstrap,,Turner|     [C, Python]|\n",
            "+-----------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating dataFrame with nested structure using Row class\n",
        "data=[Row(name=\"Jack\",character=Row(hair=\"black\",eye=\"blue\")),\n",
        "      Row(name=\"Ann\",character=Row(hair=\"grey\",eye=\"black\"))]\n",
        "df=spark.createDataFrame(data)\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpTSxN_koqdl",
        "outputId": "afe7d0de-477e-4881-fc1f-a6e656fa4d11"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+\n",
            "|name|    character|\n",
            "+----+-------------+\n",
            "|Jack|{black, blue}|\n",
            "| Ann|{grey, black}|\n",
            "+----+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}